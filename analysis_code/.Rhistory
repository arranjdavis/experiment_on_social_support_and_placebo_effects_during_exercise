plot(tobit.Q2$linear.predictors, question_data$Q2_ans_perc, ylab = "Observed values", xlab = "Predicted values")
#(look for random pattern around 0)
plot(fitted(tobit_Q2), resid(tobit_Q2), ylab = "Residuals", xlab = "Fitted values")
#set working directory to the assumption check folder for this model
file_path = "../multilevel_censored_regression_model_on_perceived_difficulty/"
setwd(file_path)
################################################################################################################################################
### MULTILEVEL CENSORED REGRESSION MODEL ON POST EXERCISE TRIAL QUESTION ON PERCEIVED DIFFUCULTY - LEVEL-ONE LINEARITY AND HOMOSCEDASTICITY ###
#plot fitted values v. residual values
jpeg('fitted_v_residual_plot.jpeg', width = 5, height = 5, units = "in",res = 300, pointsize = 12, quality = 100)
plot(fitted(tobit_Q2), resid(tobit_Q2), ylab = "Residuals", xlab = "Fitted values")
dev.off()
jpeg('level_one_residual_qq_plot.jpeg', width = 5, height = 5, units = "in",res = 300, pointsize = 12, quality = 100)
qqnorm(residuals(tobit_Q2), main = "")
qqline(residuals(tobit_Q2))
dev.off()
#get the variance inflation factor (VIF) range
cat(paste("Variance inflation factor (VIF) range:", range(vif(tobit_Q2)[,1])), file = 'assumption_tests.txt', append=TRUE)
#this will get the mean VIF
y = sqrt(vif(tobit_Q2))
cat(paste("Variance inflation factor (VIF) mean:", mean(y[,1]^2)), file = 'assumption_tests.txt', append=TRUE)
#get the variance inflation factor (VIF) range
cat(paste("Variance inflation factor (VIF) range:", range(vif(tobit_Q2)[,1])), file = 'assumption_tests.txt', append=TRUE)
#this will get the mean VIF
y = sqrt(vif(tobit_Q2))
cat(paste("\nVariance inflation factor (VIF) mean:", mean(y[,1]^2)), file = 'assumption_tests.txt', append=TRUE)
range(vif(tobit_Q2)[,1])
range(vif(tobit_Q2)[,1])[1]
#get the variance inflation factor (VIF) range
cat(paste("Variance inflation factor (VIF) range:", range(vif(tobit_Q2)[,1])[1], ", ", range(vif(tobit_Q2)[,1])[2]), file = 'assumption_tests.txt', append=TRUE)
#this will get the mean VIF
y = sqrt(vif(tobit_Q2))
cat(paste("\nVariance inflation factor (VIF) mean:", mean(y[,1]^2)), file = 'assumption_tests.txt', append=TRUE)
#get the variance inflation factor (VIF) range
cat(paste0("Variance inflation factor (VIF) range: ", range(vif(tobit_Q2)[,1])[1], ", ", range(vif(tobit_Q2)[,1])[2]), file = 'assumption_tests.txt', append=TRUE)
#this will get the mean VIF
y = sqrt(vif(tobit_Q2))
cat(paste("\nVariance inflation factor (VIF) mean:", mean(y[,1]^2)), file = 'assumption_tests.txt', append=TRUE)
#get the random intercepts for the model
vrtm.re = ranef(Q2_results_full_model, condVar = TRUE, standard = TRUE)
#get the random intercepts for the model
mod_re = ranef(Q2_results_full_model, condVar = TRUE, standard = TRUE)
str(mod_re)
#get a dataset of all non-standardized Empirical Bayes (EB) residuals (use this for level-two fixed effects; Snijders & Bosker, 2012; p. 64)
postmean = mod_re$Participant[,1]
postmean
#posterior variances
postmeanvar = attr(mod_re$Participant, 'postVar')[1,1,]
#diagnostic variances
diagmeanvar = VarCorr(Q2_results_full_model)$Participant[1,1] - postmeanvar
diagmeanvar
postmeanvar
postmean
attr(mod_re$Participant, 'postVar')
#level-two normality
postmean.stand <- postmean/sqrt(diagmeanvar)
#level-two normality
postmean.stand = postmean/sqrt(diagmeanvar)
postmean.stand
qqnorm(postmean_stand, main = "")
#level-two normality
postmean_stand = postmean/sqrt(diagmeanvar)
qqnorm(postmean_stand, main = "")
qqline(postmean_stand)
shapiro.test(postmean_stand)
#get the random intercepts for the model
mod_re = ranef(Q2_results_full_model, condVar = TRUE, standard = TRUE)
#get a dataset of all non-standardized Empirical Bayes (EB) residuals (use this for level-two fixed effects; Snijders & Bosker, 2012; p. 64)
postmean = mod_re$Participant[,1]
#posterior variances
postmeanvar = attr(mod_re$Participant, 'postVar')[1,1,]
#diagnostic variances
diagmeanvar = VarCorr(Q2_results_full_model)$Participant[1,1] - postmeanvar
#standardised level-two random intercept residuals
postmean_stand = postmean/sqrt(diagmeanvar)
#plot standardised level-two random intercept residual normality
jpeg('level_two_residual_normality_intercepts.jpeg', width = 5, height = 5, units = "in",res = 300, pointsize = 12, quality = 100)
qqnorm(postmean_stand, main = "")
qqline(postmean_stand)
dev.off()
#perform a Shapiro-Wilks test
shapiro.test(postmean_stand)
#perform a Shapiro-Wilks test
shapiro.test(postmean_stand)[1]
shapiro.test(postmean_stand)[2]
print(shapiro.test(postmean_stand)[2])
as.numeric(shapiro.test(postmean_stand)[2])
#perform a Shapiro-Wilks test
sw_w = as.numeric(shapiro.test(postmean_stand)[1])
sw_p = as.numeric(shapiro.test(postmean_stand)[2])
mean(y[,1]^2))
mean(y[,1]^2)
cat(paste("\nVariance inflation factor (VIF) SD:", sd(y[,1]^2)), file = 'assumption_tests.txt', append=TRUE)
vif(tobit_Q2)
#this will get the mean VIF for all the predictor variables
y = sqrt(vif(tobit_Q2))
y
y[,1]^2
vif(tobit_Q2)
vif(tobit_Q2)[, 1]
vif(tobit_Q2)[c(1:6), 1]
mean(vif(tobit_Q2)[c(1:6), 1])
range(vif(tobit_Q2)[c(1:6), 1])[1]
range(vif(tobit_Q2)[c(1:6), 1])[1]
range(vif(tobit_Q2)[c(1:6), 1])[2])
range(vif(tobit_Q2)[c(1:6), 1])
cat(paste("\nVariance inflation factor (VIF) mean:", mean(vif(tobit_Q2)[c(1:6), 1]), file = 'assumption_tests.txt', append=TRUE)
cat(paste("\nVariance inflation factor (VIF) mean:", mean(vif(tobit_Q2)[c(1:6), 1])), file = 'assumption_tests.txt', append=TRUE)
cat(paste("\nVariance inflation factors (VIF) for each predictor:", vif(tobit_Q2)[c(1:6), 1], file = 'assumption_tests.txt', append=TRUE)
cat(paste("\nVariance inflation factors (VIF) for each predictor:", vif(tobit_Q2)[c(1:6), 1]), file = 'assumption_tests.txt', append=TRUE)
vif(tobit_Q2)[c(1:6), 1])
vif(tobit_Q2)[c(1:6), 1]
vif(tobit_Q2)[c(1:6), 1]
vif(tobit_Q2)[c(1:6), 1][1]
################################################################################################################################################
### MULTILEVEL CENSORED REGRESSION MODEL ON POST EXERCISE TRIAL QUESTION ON PERCEIVED DIFFUCULTY - MULTICOLLINEARITY ###
#get the variance inflation factor (VIF) range
cat(paste0("Variance inflation factor (VIF) range: ", range(vif(tobit_Q2)[c(1:6), 1])[1], ", ", range(vif(tobit_Q2)[c(1:6), 1])[2]), file = 'assumption_tests.txt', append=TRUE)
#this will get the mean VIF for all the predictor variables
cat(paste("\nVariance inflation factor (VIF) mean:", mean(vif(tobit_Q2)[c(1:6), 1])), file = 'assumption_tests.txt', append=TRUE)
#get the VIF for each predictor
cat(paste("\nVariance inflation factors (VIF) for social support condition predictor:", vif(tobit_Q2)[c(1:6), 1][1]), file = 'assumption_tests.txt', append=TRUE)
cat(paste("\nVariance inflation factors (VIF) for placebo condition predictor:", vif(tobit_Q2)[c(1:6), 1][2]), file = 'assumption_tests.txt', append=TRUE)
cat(paste("\nVariance inflation factors (VIF) for target trial difficulty condition predictor:", vif(tobit_Q2)[c(1:6), 1][3]), file = 'assumption_tests.txt', append=TRUE)
cat(paste("\nVariance inflation factors (VIF) for exercise block predictor:", vif(tobit_Q2)[c(1:6), 1][4]), file = 'assumption_tests.txt', append=TRUE)
cat(paste("\nVariance inflation factors (VIF) for exercise trial number predictor:", vif(tobit_Q2)[c(1:6), 1][5]), file = 'assumption_tests.txt', append=TRUE)
#perform a Shapiro-Wilks test
sw_w = as.numeric(shapiro.test(postmean_stand)[1])
cat(paste0("\n\nShapiro-Wilks test of level-two residual normality: W = ", sw_w, ", p = ", sw_p), file = 'assumption_tests.txt', append=TRUE)
#plot standardised level-two random intercept residual normality
jpeg('level_two_residual_normality_intercepts.jpeg', width = 5, height = 5, units = "in",res = 300, pointsize = 12, quality = 100)
qqnorm(postmean_stand, main = "")
qqline(postmean_stand)
dev.off()
#a function for checking the influence of level-two units (participants) using Cook's distances
check_influence(Q2_results_full_model, "Participant")
summary(placeb_exercise_block_interaction)
#test the interaction between placebo and exercise block; this is the most complex random effects structure that allows for convergence
placebo_exercise_block_interaction = lmer(percent_of_maximum ~ placebo_condition*session_number + trial_number + sex + Q1_ans_perc + (1 + placebo_condition | Participant), data = total_data)
summary(placebo_exercise_block_interaction)
summary(cens_reg_session_placebo_interaction)
#get the mean, sd, and range of responses to the question about whether participants felt that the beta-alanine (i.e., the placebo) significantly improved their performance
mean(post_experiment_data$beta_alanine_performance_effect)
sd(post_experiment_data$beta_alanine_performance_effect)
range(post_experiment_data$beta_alanine_performance_effect)
#one sample t-test to see if scores differ from 0 (make 50 or "no difference" equal 0)
post_experiment_data$beta_alanine_performance_effect = post_experiment_data$beta_alanine_performance_effect - 50
t.test(post_experiment_data$beta_alanine_performance_effect)
post_experiment_data
post_experiment_data$beta_alanine_performance_effect
#get the mean, sd, and range of responses to the question about whether participants felt that the beta-alanine (i.e., the placebo) significantly improved their performance
mean(post_experiment_data$beta_alanine_performance_effect)
sd(post_experiment_data$beta_alanine_performance_effect)
range(post_experiment_data$beta_alanine_performance_effect)
#these analyses need to be run on a data set that has just one row per trial, since each question is answered only once per trial (the first row and the last row will be the same - only the voltage / hand-grip data changes)
question_data = subset(total_data, sample_reading_number == 1)
#get one row per participant (this will get the data for the pre- and post-experiment questions)
post_experiment_data = subset(question_data, trial_number == 1 & session_number == 1)
### ### ###
#number of participants who had heard of beta-alanine
table(post_experiment_data$heard_of_beta_alanine)[3]
#percentage of participants who had heard of beta-alanine
(table(post_experiment_data$heard_of_beta_alanine)[3] / sum(table(post_experiment_data$heard_of_beta_alanine))) * 100
### ### ##
#get the mean, sd, and range of responses to the question about whether participants felt that the beta-alanine (i.e., the placebo) significantly improved their performance
mean(post_experiment_data$beta_alanine_performance_effect)
sd(post_experiment_data$beta_alanine_performance_effect)
range(post_experiment_data$beta_alanine_performance_effect)
#one sample t-test to see if scores differ from 0 (make 50 or "no difference" equal 0)
post_experiment_data$beta_alanine_performance_effect = post_experiment_data$beta_alanine_performance_effect - 50
t.test(post_experiment_data$beta_alanine_performance_effect)
mean(post_experiment_data$beta_alanine_difficulty_effect)
sd(post_experiment_data$beta_alanine_difficulty_effect)
range(post_experiment_data$beta_alanine_difficulty_effect)
#one sample t-test to see if scores differ from 0 (make 50 or "no difference" equal 0)
post_experiment_data$beta_alanine_difficulty_effect = post_experiment_data$beta_alanine_difficulty_effect - 50
t.test(post_experiment_data$beta_alanine_difficulty_effect)
#get the mean, sd, and range of responses to the question on how close participants felt to their support figure whose photo they saw during the experiment
mean(post_experiment_data$close_to_support_figure_during_exercise)
sd(post_experiment_data$close_to_support_figure_during_exercise)
range(post_experiment_data$close_to_support_figure_during_exercise)
#get the mean, sd, and range of responses to the question on how close participants felt to the stranger whose photo they saw during the experiment
mean(post_experiment_data$close_to_stranger_during_exercise)
sd(post_experiment_data$close_to_stranger_during_exercise)
range(post_experiment_data$close_to_stranger_during_exercise)
#do a Wilcoxon rank-sum test (paired samples, since measures are from the same participant)
wilcox.test(post_experiment_data$close_to_support_figure_during_exercise, post_experiment_data$close_to_stranger_during_exercise, paired = TRUE)
summary(cens_reg_final_model)
as.data.frame(summary(cens_reg_final_model)["estimate"])[
as.data.frame(summary(cens_reg_final_model)["estimate"])
as.data.frame(summary(cens_reg_final_model)["estimate"])[5,1]
int_est = as.data.frame(summary(cens_reg_final_model)["estimate"])[5,1]
int_se = as.data.frame(summary(cens_reg_final_model)["estimate"])[5,2]
print(paste("UPPER 95% CI:", int_est + 1.96*int_se))
print(paste("LOWER 95% CI:", int_est - 1.96*int_se))
#create a list of all participants with data
participants = unique(total_data$Participant)
#find participants whose voltage data was not recorded (due to equipment malfunctions)
all_participant_numbers = min(as.numeric(total_data$Participant)):max(as.numeric(total_data$Participant))
print(all_participant_numbers[!all_participant_numbers %in% participants])
#loads the final data set
total_data = read.csv("../data/total_combined_data.csv", sep = ",")
################################################################################################################################################
### REMOVAL OF PARTICIPANTS WHO DID NOT FOLLOW EXPERIMENTAL INSTRUCTIONS ###
#create a list of all participants with data
participants = unique(total_data$Participant)
#find participants whose voltage data was not recorded (due to equipment malfunctions)
all_participant_numbers = min(as.numeric(total_data$Participant)):max(as.numeric(total_data$Participant))
print(all_participant_numbers[!all_participant_numbers %in% participants])
#clean environment
rm(list= ls())
#set current working directory to the one this script is in (when in RStudio)
code_dir = dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(code_dir)
#loads the final data set
total_data = read.csv("../data/total_combined_data.csv", sep = ",")
################################################################################################################################################
### REMOVAL OF PARTICIPANTS WHO DID NOT FOLLOW EXPERIMENTAL INSTRUCTIONS ###
#create a list of all participants with data
participants = unique(total_data$Participant)
#find participants whose voltage data was not recorded (due to equipment malfunctions)
all_participant_numbers = min(as.numeric(total_data$Participant)):max(as.numeric(total_data$Participant))
print(all_participant_numbers[!all_participant_numbers %in% participants])
#clean environment
rm(list= ls())
#set current working directory to the one this script is in (when in RStudio)
code_dir = dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(code_dir)
################################################################################################################################################
### THIS WILL CREATE A DATA FRAME OF THE VOLTAGE DATA (THE MEASURE OR PARTICIPANTS' PERFORMANCE ON THE EXERCISE TASK) ###
library(R.matlab)
#folder containing voltage data
datfolder = "../data/matlab_results/"
#this takes all the subfolders in the results folder
subfolders = list.dirs(datfolder)
l = (1 + length(subfolders))
subfolders = subfolders[2:l]
#skip the last subfolder (NA)
subfolders = subfolders[1:(length(subfolders) - 1)]
#counter for the for loop below
count = 1
#list for all the numbers of voltage readings (the minumum per session)
totreadings = list()
#this will get the minimum number of voltage readings for a given trial in each experimental session
for (i in subfolders) {
#track progress
print(paste0("CURRENT FOLDER: ", i))
#get the data
sub1 = subfolders[count]
files1 = list.files(sub1)
#this gets the MATLAB file with the voltage data
D = readMat(paste(sub1, files1[1], sep = '/'))
#this gets the voltage data (its a list of 42, since there are 42 trials)
voltage = D$record.V
#this for loop will get the number of voltage readings for each trial
#this creates a list to see the minimum amount of voltage readings in the sessions (so the smallest number for the 42 trials)
sess_readings = list()
#counter for the for loop below
count2 = 1
#this will go through all the trials and get the number of readings
for (i in voltage) {
cur_trial = voltage[count2]
trial_readings = ncol(as.data.frame(cur_trial))
sess_readings = append(sess_readings, trial_readings)
count2 = count2 +1
}
#flips 'sess_readings' so that its a matrix with one column and 42 rows
sess_readings = t(sess_readings)
#makes it a data frame
p = as.data.frame(sess_readings)
#flips it so that it has only one column
p = t(p)
#make data frame again
p = as.data.frame(p)
#convert from a list to numeric and get the minimum value (for the variable 'V1,' which is the only column)
minimum_trial_readings = min(as.numeric(p$V1))
#now add the minumum for this session to the list of all the minimum readings for all the sessions
totreadings = append(totreadings, minimum_trial_readings)
count = count + 1
}
#this gets the minimum reading from all trials from all the sessions for all participants
q = as.data.frame(totreadings)
q = t(q)
q = as.data.frame(q)
grand_minimum = min(as.numeric(q$V1))
################################################################################################################################################
### RESAMPLE ALL TRIALS SO THAT EACH TRIAL HAS THE GRAND MINIMUM NUMBER OF VOLTAGE READINGS (160 OR 20 READINGS PER SECOND) ###
#this creates an empty data frame to be filled with the resampled (160) voltage readings from each trial for each participant
total_data = data.frame()
#counter for the for loop below
count3 = 1
#this for loop will go through all the trials for each session for all the participants and resample the voltage readings
for (i in subfolders) {
#set the seed for random sampling
set.seed(count3)
#track progress
print(paste0("CURRENT FOLDER: ", i))
#get the data
sub1 = subfolders[count3]
files1 = list.files(sub1)
#this gets the MATLAB file with the voltage data
D = readMat(paste(sub1, files1[1], sep = '/'))
#this gets the MATLAB file with the other data (condition, etc)
E = readMat(paste(sub1, files1[2], sep = '/'))
tempdat = as.data.frame(E$record.dat[,1:21])
tempdat$participant = E$subDetails[1]
tempdat$placebo = E$subDetails[5]
#variable names
headings = c('trial', #1
'supp_cont', #2 - 1 equals the supportive face, 2 equals the control face
'start_time', #3
'NAN1', #4
'Q1_start_time', #5
'Q2_start_time', #6
'blank1', #7
'q1_response_time', #8
'q2_response_time', #9
'blank2', #10
'NAN2', #11
'Q1_start_pos', #12
'Q2_start_pos', #13
'blank3', #14
'Q1_ans_pos', #15
'Q2_ans_pos', #16
'blank4', #17
'Q1_ans_perc', #18
'Q2_ans_perc', #19
'blank5', #20
'trial_difficulty', #21
'participant', #22
'placebo') #23
colnames(x = tempdat) = headings
#this gets the current participant's number
participant_number = as.character(tempdat$participant[1:1])
#this gets the current participant's placebo condition
participant_placebo = as.character(tempdat$placebo[1:1])
#this gets the current participant's experimental session number (first or second)
session_number = as.numeric(D$subDetails[4])
#this gets the current participant's maximum grip strength reading (during the grip strength test)
max_grip = as.numeric(D$subDetails[6])
#this gets the current participant's minimum grip reading (during the grip strength test)
min_grip = as.numeric(D$subDetails[7])
#this gets the current participant's grip strength
grip_strength = (min_grip - max_grip)
#this gets the voltage data (its a list of 42, since there are 42 trials)
voltage = D$record.V
#counter for the for loop below
count4 = 1
#this for loop will go through all the trials in the current session and resample the voltage readings so that there are 160
#it will then add these 160 readings to a data set along with the participant number and condition
#there are 42 lists in voltage
for (i in voltage) {
#this gets the trial difficulty of the current trial (i will range from 1 to 42 - the number of trials per session)
trial_diff = as.numeric(tempdat$trial_difficulty[count4])
#this gets the face (support or control) for the current trial (it will range from 1 to 42 - the number of trials per session)
support_control = as.numeric(tempdat$supp_cont[count4])
#this gets the voltage data for the current trial
current_dat = as.data.frame(voltage[count4])
#this makes the data frame one variable
current_dat = t(current_dat)
#this renames the row names from "X1" to "1"
row.names(current_dat) = sub("X","", row.names(current_dat))
#this samples 160 voltage readings (they will not be in order in 'sampled_volt')
sample_volt = as.data.frame(current_dat[sample(nrow(current_dat), 160), ])
#this changes the name of the column
colnames(sample_volt) = 'voltage'
#this creates a variable that is the same as the row names, and then sorts by this variable (same as sorting by row)
sample_volt$reading_number = as.numeric(row.names(sample_volt))
ordered_sample_volt = sample_volt[order(sample_volt$reading_number), ]
#this creates a variable that is 1 - 160 ('reading_number' will vary from 1 - 240)
x = row(ordered_sample_volt)
ordered_sample_volt["sample_reading_number"] = x
#now add all the other variables for the particular trial
#this adds the trial difficulty
ordered_sample_volt["trial_difficulty"] = trial_diff
#this adds if the trial was with a support or control face
ordered_sample_volt["support_or_control"] = support_control
#this adds whether the trial was in the placebo or control condition
ordered_sample_volt["placebo_condition"] = participant_placebo
#this adds the experimental session number of the trial (first or second)
ordered_sample_volt["session_number"] = session_number
#this adds the trial number
ordered_sample_volt["trial_number"] = count4
#this adds the maximum grip
ordered_sample_volt["max_grip"] = max_grip
#this adds the minimum grip
ordered_sample_volt["min_grip"] = min_grip
#this adds the grip strength
ordered_sample_volt["grip_strength"] = grip_strength
#this adds the participant number (making it the first column)
ordered_sample_volt = cbind(participant = participant_number, ordered_sample_volt)
#add to counter
count4 = count4 + 1
#this adds the sample of voltage readings from the current trial to the data set with all samples from all the trials
total_data = rbind(total_data, ordered_sample_volt)
#clears the data from the last trial
rm(current_dat)
}
count3 = count3 + 1
}
#some trials are labled 'OFF' instead of 'off' for 'placebo_condition' - this fixes the labeling
total_data$placebo_condition <- ifelse(total_data$placebo_condition == "OFF", "off", ifelse(total_data$placebo_condition == "on", "on", ifelse(total_data$placebo_condition == "off", "off", NA)))
#'total_data$sample_reading_number' is a matrix with two columns; extract the first column
total_data$sample_reading_number = total_data$sample_reading_number[,1]
################################################################################################################################################
### IDENTIFY ERRONEOUS VOLTAGE DATA ###
library(dplyr)
#create voltage range data for all participants
voltage_ranges = total_data %>%
group_by(participant) %>%
summarise(volt_range = max(voltage) - min(voltage))
#examine the voltage ranges
hist(voltage_ranges$volt_range, breaks = 100)
#get the mean and SD of the voltage ranges
vr_mean = mean(voltage_ranges$volt_range)
vr_sd = sd(voltage_ranges$volt_range)
#find the outlying participant
outlier = subset(voltage_ranges, voltage_ranges$volt_range > (vr_mean + (vr_sd*2)))
#remove the outlying participant from the dataset
total_data = subset(total_data, participant != as.character(outlier$participant))
total_data$participant = droplevels(total_data$participant)
outlier
#get the mean and SD of the voltage ranges
vr_mean = mean(voltage_ranges$volt_range)
vr_mean
vr_sd
vr_mean
vr_sd
subset(voltage_ranges, voltage_ranges$volt_range > (vr_mean + (vr_sd*2)))
mean(outlier$volt_range)
print(paste0("OUTLIER VOLTAGE RANGE: ", mean(outlier$volt_range))
print(paste0("OUTLIER VOLTAGE RANGE: ", mean(outlier$volt_range)))
print(paste0("OUTLIER VOLTAGE RANGE: ", mean(outlier$volt_range)))
print(paste0("MEAN VOLTAGE RANGE: ", vr_mean))
1943.1 / 270.48012718505
vr_sd
1943.1 - 270.48012718505
(1943.1 - 270.48012718505) / 193.7525
print(paste0("OUTLIER VOLTAGE RANGE: ", mean(outlier$volt_range)))
#clean environment
rm(list= ls())
#set current working directory to the one this script is in (when in RStudio)
code_dir = dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(code_dir)
#loads the final data set
total_data = read.csv("../data/total_combined_data.csv", sep = ",")
################################################################################################################################################
### REMOVAL OF PARTICIPANTS WHO DID NOT FOLLOW EXPERIMENTAL INSTRUCTIONS ###
#create a list of all participants with data
participants = unique(total_data$Participant)
#find participants whose voltage data was not recorded (due to equipment malfunctions)
all_participant_numbers = min(as.numeric(total_data$Participant)):max(as.numeric(total_data$Participant))
print(all_participant_numbers[!all_participant_numbers %in% participants])
### ### ###
#make the 'Participant' variable a factor
total_data$Participant = as.factor(total_data$Participant)
#a list of participants who were not following the experimental instructions
slacking = c()
#go through all the participants and calculate average percentage of total grip strength for each difficulty level
for (i in participants) {
#subsets data by participant and for each difficulty level
trial_diff_1 = subset(total_data, Participant == i & trial_difficulty == 1)
trial_diff_2 = subset(total_data, Participant == i & trial_difficulty == 2)
trial_diff_3 = subset(total_data, Participant == i & trial_difficulty == 3)
#gets participant i's mean percentage of maximum grip strength for each difficulty level
mean_td1 = mean(trial_diff_1$percent_of_maximum)
mean_td2 = mean(trial_diff_2$percent_of_maximum)
mean_td3 = mean(trial_diff_3$percent_of_maximum)
#identify any participant whose average grip strength does not increase with trial difficulty (indicating they did not try to meet their target grip strengths)
if (mean_td1 < mean_td2 & mean_td2 < mean_td3){
} else {
slacking = append(slacking, i)
}
}
#print a list of the the participants who were slacking
unique(slacking)
#create a list of all participants with data
participants = unique(total_data$Participant)
#find participants whose voltage data was not recorded (due to equipment malfunctions)
all_participant_numbers = min(as.numeric(total_data$Participant)):max(as.numeric(total_data$Participant))
print(all_participant_numbers[!all_participant_numbers %in% participants])
min(as.numeric(total_data$Participant))
participants
as.numeric(as.character(unique(total_data$Participant)))
#create a list of all participants with data
participants = as.numeric(as.character(unique(total_data$Participant)))
all_participant_numbers = min(as.numeric(total_data$Participant)):max(as.numeric(total_data$Participant))
print(all_participant_numbers[!all_participant_numbers %in% participants])
#find participants whose voltage data was not recorded (due to equipment malfunctions)
all_participant_numbers = min(participants):max(participants)
all_participant_numbers
print(all_participant_numbers[!all_participant_numbers %in% participants])
#make the 'Participant' variable a factor
total_data$Participant = as.factor(total_data$Participant)
#print a list of the the participants who were slacking
unique(slacking)
#remove all data from participants who did not follow the experimental instructions to increase grip strength with trial difficulty
slacker_data = total_data[total_data$Participant %in% slacking, ]
total_data = total_data[ ! total_data$Participant %in% slacking, ]
total_data$Participant = droplevels(total_data$Participant)
#find all participants who were removed from analyses
final_participants = unique(total_data$Participant)
print(all_participant_numbers[!all_participant_numbers %in% final_participants])
#hand-grip strength by trial difficulty
group_by(total_data, trial_difficulty) %>% summarise(volt_mean = mean(percent_of_maximum, na.rm = TRUE))
#hand-grip strength by trial difficulty
group_by(total_data, trial_difficulty) %>% summarise(grip_mean = mean(percent_of_maximum, na.rm = TRUE)
grip_sd = sd(percent_of_maximum, na.rm = TRUE))
group_by(total_data, trial_difficulty) %>% summarise(grip_mean = mean(percent_of_maximum, na.rm = TRUE),
grip_sd = sd(percent_of_maximum, na.rm = TRUE))
group_by(slacker_data, trial_difficulty) %>% summarise(grip_mean = mean(percent_of_maximum, na.rm = TRUE),
grip_sd = sd(percent_of_maximum, na.rm = TRUE))
